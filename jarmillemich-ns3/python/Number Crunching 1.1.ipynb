{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number Crunching I\n",
    "\n",
    "This notebook is mostly to mess around with loading the data,\n",
    "as well as trimming and reserializing the columns we care about\n",
    "in a lighter (\\~20% size), and faster (~15x load) format (gzipped parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkPath(name, direction, trajectory, run, users, radius, ul, dl):\n",
    "    return './out/%s%s_%s_run%d_usr%d_rad%.2f_ul%d_dl%d.txt' % (direction, name, trajectory, run, users, radius, ul, dl)\n",
    "    \n",
    "def readRlcStats(direction, trajectory, run, users, radius, ul, dl):\n",
    "    fname = mkPath('RlcStats', direction, trajectory, run, users, radius, ul, dl)\n",
    "\n",
    "    frame = pd.read_csv(fname, sep='\\t', index_col=False,\n",
    "                        header=0L,\n",
    "                        names=[\n",
    "                            'start', 'end',\n",
    "                            'cellId', 'IMSI', 'RNTI', 'LCID',\n",
    "                            'nTxPDUs', 'TxBytes', 'nRxPDUs', 'RxBytes',\n",
    "                            'delay', 'delay.stdDev', 'delay.min', 'delay.max',\n",
    "                            'PduSize', 'PduSize.stdDev', 'PduSize.min', 'PduSize.max'\n",
    "                        ],\n",
    "                        usecols=[\n",
    "                            'start', 'end',\n",
    "                            'cellId', 'IMSI', #'RNTI', 'LCID',\n",
    "                            'nTxPDUs', 'TxBytes', 'nRxPDUs', 'RxBytes',\n",
    "                            'delay', 'delay.stdDev', 'delay.min', 'delay.max',\n",
    "                            'PduSize', 'PduSize.stdDev', 'PduSize.min', 'PduSize.max'\n",
    "                        ],\n",
    "                        dtype={\n",
    "                            'start': 'float32', 'end': 'float32',\n",
    "\n",
    "                            'cellId': 'UInt8', 'IMSI': 'UInt8', 'LCID': 'UInt8',\n",
    "\n",
    "                            'nTxPDUs': 'UInt16', 'TxBytes': 'float32',\n",
    "                            'nRxPDUs': 'UInt16', 'RxBytes': 'float32',\n",
    "\n",
    "                            'delay':     'float32', 'delay.stdDev': 'float32',\n",
    "                            'delay.min': 'float32', 'delay.max':    'float32',\n",
    "\n",
    "                            'PduSize':     'float32', 'PduSize.stdDev': 'float32',\n",
    "                            'PduSize.min': 'float32', 'PduSize.max':    'float32',\n",
    "                        }\n",
    "                    )\n",
    "    \n",
    "\n",
    "    frame.start = pd.to_timedelta(frame.start, 's')\n",
    "    frame.end = pd.to_timedelta(frame.end, 's')\n",
    "    \n",
    "    # Make time column the index\n",
    "    frame.set_index('start', inplace=True)\n",
    "    \n",
    "    return frame\n",
    "    \n",
    "def readDlRsrpSinrStats(trajectory, run, users, radius, ul, dl):\n",
    "    fname = mkPath('RsrpSinrStats', 'Dl', trajectory, run, users, radius, ul, dl)\n",
    "\n",
    "    frame = pd.read_csv(fname, sep='\\t', index_col=False,\n",
    "                        header=0L,\n",
    "                        names=  ['time', 'cellId', 'IMSI', 'RNTI', 'rsrp', 'sinr', 'ComponentCarrierId'],\n",
    "                        usecols=['time', 'cellId', 'IMSI', 'rsrp', 'sinr'],\n",
    "                        dtype={\n",
    "                            'time': 'float32',\n",
    "                            'cellId': 'UInt8', 'IMSI': 'UInt8', 'RNTI': 'UInt8',\n",
    "                            'rsrp': 'float32', 'sinr': 'float32',\n",
    "                            'ComponentCarrierId': 'UInt8'\n",
    "                        }\n",
    "                       )\n",
    "\n",
    "    # Convert SINR, RSRP to dB\n",
    "    frame.sinr = 10 * np.log10(frame.sinr)\n",
    "    frame.rsrp = 10 * np.log10(frame.rsrp)\n",
    "\n",
    "    frame.time = pd.to_timedelta(frame.time, 's')\n",
    "    \n",
    "    # Make time column the index\n",
    "    frame.set_index('time', inplace=True)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def readUlSinrStats(trajectory, run, users, radius, ul, dl):\n",
    "    fname = mkPath('SinrStats', 'Ul', trajectory, run, users, radius, ul, dl)\n",
    "\n",
    "    frame = pd.read_csv(fname, sep='\\t', index_col=False,\n",
    "                        header=0L,\n",
    "                        names=['time', 'cellId', 'IMSI', 'RNTI', 'sinr', 'componentCarrierId'],\n",
    "                        usecols=['time', 'cellId', 'IMSI', 'sinr'],\n",
    "                        dtype={\n",
    "                            'time': 'float32',\n",
    "                            'cellId': 'UInt8', 'IMSI': 'UInt8', 'RNTI': 'UInt8',\n",
    "                            'sinr': 'float32', 'ComponentCarrierId': 'UInt8'\n",
    "                        }\n",
    "                       )\n",
    "\n",
    "    # Convert SINR, RSRP to dB\n",
    "    frame.sinr = 10 * np.log10(frame.sinr)\n",
    "    \n",
    "    frame.time = pd.to_timedelta(frame.time, 's')\n",
    "\n",
    "    # Make time column the index\n",
    "    #frame.set_index(['time', 'IMSI'], inplace=True)\n",
    "    frame.set_index('time', inplace=True)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def readApplicationStats(clientServer, trajectory, run, users, radius, ul, dl):\n",
    "    fname = mkPath('Stats', clientServer, trajectory, run, users, radius, ul, dl)\n",
    "    \n",
    "    frame = pd.read_csv(fname, index_col=False)\n",
    "    frame.rename(columns={ frame.columns[0]: 'time' }, inplace=True)\n",
    "    frame.time = pd.to_timedelta(frame.time, 'min')\n",
    "    frame.time = frame.time.round('s') # To correct our terrible encoding choices\n",
    "    frame.set_index(['time'], inplace=True)\n",
    "\n",
    "    # Correct integer overflows in byte counts\n",
    "    frame[frame < -(2**30)] += 2**32\n",
    "    \n",
    "    # Unpivot the flowId into an index\n",
    "    frame = pd.melt(frame, var_name='flowId', value_name='bytes', ignore_index=False)\n",
    "    frame.flowId = frame.flowId.astype('uint8')\n",
    "    #frame.set_index('flowId', append=True, inplace=True)\n",
    "    \n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkPathPacked(name, trajectory, run, users, radius, ul, dl):\n",
    "    return './packed2/%s_%s_run%d_usr%d_rad%.2f_ul%d_dl%d.parquet.gzip' % (name, trajectory, run, users, radius, ul, dl)\n",
    "\n",
    "\n",
    "def compressRun(trajectory, run, users, radius, ul, dl):\n",
    "    args={'trajectory': trajectory, 'run': run, 'users': users, 'radius': radius, 'ul': ul, 'dl': dl}\n",
    "    dlSinr, ulSinr, dlRlc, ulRlc, serverStats, clientStats = (\n",
    "        readDlRsrpSinrStats(**args), readUlSinrStats(**args),\n",
    "        readRlcStats('Dl', **args), readRlcStats('Ul', **args),\n",
    "        readApplicationStats('server', **args), readApplicationStats('client', **args)\n",
    "    )\n",
    "    \n",
    "    dlSinr.to_parquet(mkPathPacked('dlSinr', **args), compression='gzip', engine='fastparquet')\n",
    "    ulSinr.to_parquet(mkPathPacked('ulSinr', **args), compression='gzip', engine='fastparquet')\n",
    "    dlRlc.to_parquet(mkPathPacked('dlRlc', **args), compression='gzip', engine='fastparquet')\n",
    "    ulRlc.to_parquet(mkPathPacked('ulRlc', **args), compression='gzip', engine='fastparquet')\n",
    "    \n",
    "    serverStats.to_parquet(mkPathPacked('serverStats', **args), compression='gzip', engine='fastparquet')\n",
    "    clientStats.to_parquet(mkPathPacked('clientStats', **args), compression='gzip', engine='fastparquet')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e715ed5711c740d0ac661ca7c9a7f0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, min=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool\n",
    "from queue import Queue\n",
    "\n",
    "q = []\n",
    "\n",
    "def doWork(args):\n",
    "    compressRun(*args)\n",
    "    \n",
    "\n",
    "# Adjust this for whatever we need to compress\n",
    "for i in list(range(5, 10)) + list(range(15,20)) + list(range(25,30)):\n",
    "    for traj in ['nm-0Wh-r0', 'nm-500Wh-r0', 'pso-0Wh-r0', 'pso-500Wh-r0']:\n",
    "        q.append((traj, i, 5, 5, False, True))\n",
    "    \n",
    "with Pool(16) as p:\n",
    "   r = list(tqdm(p.imap(doWork, q), total = len(q)))\n",
    "\n",
    "# for i in tqdm(q):\n",
    "#   doWork(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.0",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
